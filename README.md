## Multimodal RLHF: Enhancing AI Perception
This project implements a framework for fine-tuning multi-modal networks using Reinforcement Learning from Human Feedback (RLHF). I am trying to integrate llama-3 (text), Stable Diffusion (image), and NeRF (3D scene reconstruction), so that the system improves cross-modal consistency and the aim is to reduce sensor data hallucinations. 
I will be using 10K+ human preference annotations to create more reliable AI perception systems with applications in healthcare, autonomous vehicles, and assistive technologies.
